{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOQUyKEu5h1Ud08dNCb40Zg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjosephnyc1987/public_ipython_Notebooks/blob/main/DAL_STXE_TickData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STXE Tick Data\n",
        "\n",
        "## **Prep**\n",
        "\n",
        "Our overall goal in filtering Tick data is as follows\n",
        "\n",
        "1.Remove any Rows with Null Values\n",
        "\n",
        "2.Remove a Lot that is 0 or Negative\n",
        "\n",
        "3.Remove any instructions that are not 'Bid' or 'Ask;\n",
        "\n",
        "4.Visually look at the chart (optional)\n",
        "\n",
        "5.Remove any outliers that are outside of a 2 std deviation threshold\n",
        "\n",
        "6.Remove any \"cross market quotes\"! (Bid = Offer) in the same Timeframe\n",
        "\n",
        "7.Remove any quotes where Bid > Offer\n",
        "\n",
        "8.Remove Bid-Ask Bounce"
      ],
      "metadata": {
        "id": "-R18EfCb6uyC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxM7gKmFhfFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceab9be9-6e98-426d-abb7-bc44ee14e05b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#initializations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#this is a terrible practice and dont do it\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#turn of charting to preseve compute - value = 1 draws charts\n",
        "DrawCharts = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/drive/MyDrive/TEMPO/datasets/STXE tick Data.csv\"\n",
        "\n",
        "df2 = pd.read_csv(filepath,sep='\\t', header=0)\n",
        "\n",
        "original_size = len(df2)\n",
        "print(\"original dataframe size = \", original_size)\n",
        "\n",
        "#Let's look at the first 10 rows\n",
        "print(df2.head(10))"
      ],
      "metadata": {
        "id": "YeMlyANxhl96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26dec6e4-f521-4e7c-c6da-0521569f40a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original dataframe size =  1566018\n",
            "                    Id  Index   Type              TimestampUtc  Size  Value\n",
            "0 -9223372020794013813      1  Trade  20160222 07:00:03.936984   738   2883\n",
            "1 -9223372020794013812      2      O  20160222 07:00:03.936984     0   2883\n",
            "2 -9223372020794013811      3      H  20160222 07:00:03.936984     0   2883\n",
            "3 -9223372020794013810      4      L  20160222 07:00:03.936984     0   2883\n",
            "4 -9223372020794013803      5    Bid  20160222 07:00:03.936984    20   2883\n",
            "5 -9223372020794013802      6    Ask  20160222 07:00:03.936984    41   2884\n",
            "6 -9223372020794013799      7  Trade  20160222 07:00:03.936984    10   2884\n",
            "7 -9223372020794013797      8      H  20160222 07:00:03.936984     0   2884\n",
            "8 -9223372020794013794      9    Ask  20160222 07:00:03.936984    31   2884\n",
            "9 -9223372020794013790     10  Trade  20160222 07:00:03.936984     3   2884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#next let's see if there are any nulls and if so we should remove them\n",
        "df2.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzu_AVMfssJ_",
        "outputId": "eef82157-1e01-4d35-e973-0f8e6ab1672f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id              0\n",
              "Index           0\n",
              "Type            0\n",
              "TimestampUtc    0\n",
              "Size            0\n",
              "Value           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#There appear to be some lots with Size of 0 and Negative, let's remove those and assign to a new dataframe df2_Size0_Removed\n",
        "#as they appear to be artefacts\n",
        "df2_Size0_Removed = df2[df2['Size']>0]"
      ],
      "metadata": {
        "id": "UhyIJdE_svUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's look at the first 10 rows again\n",
        "print(df2_Size0_Removed.head(10))"
      ],
      "metadata": {
        "id": "QCIUDsqKszRY",
        "outputId": "a7364461-4a2b-4793-9099-17b534b0cbce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Id  Index   Type              TimestampUtc  Size  Value\n",
            "0  -9223372020794013813      1  Trade  20160222 07:00:03.936984   738   2883\n",
            "4  -9223372020794013803      5    Bid  20160222 07:00:03.936984    20   2883\n",
            "5  -9223372020794013802      6    Ask  20160222 07:00:03.936984    41   2884\n",
            "6  -9223372020794013799      7  Trade  20160222 07:00:03.936984    10   2884\n",
            "8  -9223372020794013794      9    Ask  20160222 07:00:03.936984    31   2884\n",
            "9  -9223372020794013790     10  Trade  20160222 07:00:03.936984     3   2884\n",
            "10 -9223372020794013787     11    Ask  20160222 07:00:03.936984    28   2884\n",
            "11 -9223372020794013783     12  Trade  20160222 07:00:03.936984     1   2884\n",
            "12 -9223372020794013781     13    Ask  20160222 07:00:03.936984    27   2884\n",
            "13 -9223372020794013778     14  Trade  20160222 07:00:03.936984    27   2884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entries of Index 2,3,4 and 8 from the first 10 rows had size 0, they seem to be gone and so we're on the right track"
      ],
      "metadata": {
        "id": "jPTD-9s7tCBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we do a sanity check and look at the lenght of the dataframe now\n",
        "print(\"current dataframe size = \", len(df2_Size0_Removed))\n",
        "print(\"entries removed = \", original_size - len(df2_Size0_Removed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9Bsa1ZQs6jG",
        "outputId": "3f00340e-e2d6-409f-e490-791b1702b82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current dataframe size =  1565954\n",
            "entries removed =  64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#next we look for bad instruction types and remove them if needed\n",
        "print(df2_Size0_Removed['Type'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0jP7IX6s9yv",
        "outputId": "d1eedf86-87ba-4b2b-b6c5-6b3f73062241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bid      765381\n",
            "Ask      755135\n",
            "Trade     45437\n",
            "I             1\n",
            "Name: Type, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see a Type of \"I\" (and others) and so we remove them"
      ],
      "metadata": {
        "id": "wBJPJoMHtPdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2_inst_Removed = df2_Size0_Removed[(df2_Size0_Removed['Type']==\"Bid\") | (df2_Size0_Removed['Type']==\"Ask\") | (df2_Size0_Removed['Type']==\"Trade\")]"
      ],
      "metadata": {
        "id": "Zxi-J2XwtWbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's look at the lenght of the dataframe now\n",
        "print(len(df2_inst_Removed))\n",
        "print(\"--------\")\n",
        "\n",
        "#and the valuecounts again\n",
        "print(df2_inst_Removed['Type'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiVy212ZtaN5",
        "outputId": "24b815dc-0cc4-404a-846c-a4bd7cbd503a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1565953\n",
            "--------\n",
            "Bid      765381\n",
            "Ask      755135\n",
            "Trade     45437\n",
            "Name: Type, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for ease of handling we assign it to df3\n",
        "df3 = df2_inst_Removed.copy()"
      ],
      "metadata": {
        "id": "edz5-LeStg11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Next we plot this data to get a visual impression\n",
        "\n",
        "# Extract the date and close price columns\n",
        "timestamp = df3['TimestampUtc']\n",
        "price = df3['Value']\n",
        "\n",
        "\n",
        "if DrawCharts == 1:\n",
        "    # Create a line plot\n",
        "    plt.plot(timestamp, price)\n",
        "    plt.xlabel(\"TimeStampUtc\", fontsize=10)\n",
        "    plt.ylabel(\"price\", fontsize=10)\n",
        "    plt.title(f\"Figure 1 - plot of STXE Tickdata\",fontsize =14)\n",
        "    plt.xticks(fontsize=12)\n",
        "    plt.yticks(fontsize=12)\n",
        "    plt.rcParams['figure.figsize'] = [25, 6]\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "V8u9jN47tmOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------cached image here ----------\n",
        "\n",
        "[STXE Tick Data](https://imgur.com/a/Xw1YNqM)"
      ],
      "metadata": {
        "id": "Pe1ZvxYD0Hij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data shows outliers, so we'll set a limit to remove them and refine the analysis, but be cautious: outliers might hold valuable information, so removing them blindly can introduce bias. Think before you filter!\n",
        "\n",
        "Although there is some overlap in Bid and Offer prices, not separating them will cause good quotes to drop out and so we separate the Bids, Asks and Trades before we do the comparison to the rolling media"
      ],
      "metadata": {
        "id": "pe7xKsPNx9wX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#separating  the bids and offers\n",
        "df3_bid = df3[df3['Type']=='Bid']\n",
        "df3_ask = df3[df3['Type']=='Ask']\n",
        "df3_trade = df3[df3['Type']=='Trade']"
      ],
      "metadata": {
        "id": "cLgk2uVtyKwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3_bid['rolling_std_10']=df3_bid['Value'].rolling(10).std()\n",
        "df3_ask['rolling_std_10']=df3_ask['Value'].rolling(10).std()\n",
        "df3_trade['rolling_std_10']=df3_trade['Value'].rolling(10).std()\n",
        "\n",
        "df3_bid['rolling_mean_10']=df3_bid['Value'].rolling(10).mean()\n",
        "df3_ask['rolling_mean_10']=df3_ask['Value'].rolling(10).mean()\n",
        "df3_trade['rolling_mean_10']=df3_trade['Value'].rolling(10).mean()"
      ],
      "metadata": {
        "id": "zz9lrxumyNrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Filtering the data**\n",
        "From scientific literature, we see that the best way to filter outliers is to use a moving threshold of some kind.\n",
        "\n",
        "Our logic is as follows\n",
        "\n",
        "1.   We generate a moving standard deviation of window size = 10.\n",
        "2.   We generate a moving average of window size = 10\n",
        "3.   We generate a Top-Line and Bottom-Line threshold of 10-Moving-Average (step2)  plus or minus 10-day-std-dev (step 1)\n",
        "4.  If tick data lies outside this threshold, we reject it as artefact.\n",
        "\n",
        "This approach is similar to Bollinger Band support and resistance levels, and is typically driven by the research department. (A little out of scope for our exercise here)\n",
        "\n",
        "Although Tick Data is not Lognormal, we're using Variance as a tool to filter. This does'nt break our fundamental assumption, but note that we're not saying that the underlying distribution is Normal, we're saying that the distribution of 'Artefacts' is\n",
        "\n",
        "Although I've taken window size = 10, the right value is somewhat dynamically obtained and is typically arrived at depending on Price Categories, Notional values etc\n",
        "\n",
        "This logic only makes sense if there are more than 20 entries and so we don't filter outliers unless there are at least 20 entries.\n",
        "\n",
        "if there are less that 20 entries, we use the mean of the whole set plus or minus 10% to get the upper and lower bounds\n"
      ],
      "metadata": {
        "id": "Z6UNgqO61Sup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if len(df3_bid) > 20 :\n",
        "\n",
        "    df3_bid['rolling_median_3']=df3_bid['Value'].rolling(3).median()\n",
        "    df3_bid['rolling_mean_10']=df3_bid['Value'].rolling(10).mean()\n",
        "    df3_bid['rolling_std_10']=df3_bid['Value'].rolling(10).std()\n",
        "\n",
        "    df3_bid = df3_bid.dropna()\n",
        "\n",
        "    df3_bid['topline'] = df3_bid['rolling_mean_10'] + 1.0*df3_bid['rolling_std_10']  #filter band top = Rolling means + 1 x Moving Std Deviation\n",
        "    df3_bid['bottomline'] = df3_bid['rolling_mean_10'] - 1.0*df3_bid['rolling_std_10'] #filter band bottom = Rolling means - 1 x Moving Std Deviation\n",
        "\n",
        "    #We drop bids that are not in the range of the topline & bottomline bands\n",
        "    df3_bid_filtered = df3_bid.loc[(df3_bid['Value']<= df3_bid['topline']) & (df3_bid['Value'] >= df3_bid['bottomline']) ]\n",
        "\n",
        "    #let's see how much data we lost here\n",
        "    print(\"original =\", len(df3_bid), \" ,bids filtered = \" , len(df3_bid_filtered), \" , percentage bids removed = \", ((len(df3_bid)-len(df3_bid_filtered)) /len(df3_bid))*100 )\n",
        "\n",
        "    #let's plot the bids\n",
        "\n",
        "    if DrawCharts == 1:\n",
        "        plt.plot(df3_bid['TimestampUtc'], df3_bid['Value'],label=\"price\" )\n",
        "        plt.plot(df3_bid['TimestampUtc'], df3_bid['topline'],label=\"top\" )\n",
        "        plt.plot(df3_bid['TimestampUtc'], df3_bid['bottomline'],label=\"bottom\" )\n",
        "        plt.xlabel(\"TimeStampUtc\", fontsize=10)\n",
        "        plt.ylabel(\"price\", fontsize=10)\n",
        "        plt.title(f\"Figure 3 - plot of STXE Tickdata Bids with filteration bands\",fontsize =14)\n",
        "        plt.legend(loc=\"upper left\")\n",
        "        plt.rcParams['figure.figsize'] = [25, 6]\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"----not enough bids to use moving averages------\")  #debug\n",
        "    df3_bid['mean'] = df3_bid['Value'].mean()\n",
        "    df3_bid['topline'] = df3_bid['Value'].mean()*1.1\n",
        "    df3_bid['bottomline'] = df3_bid['Value'].mean()*0.9\n",
        "    df3_bid_filtered = df3_bid.loc[(df3_bid['Value']<= df3_bid['topline']) & (df3_bid['Value'] >= df3_bid['bottomline']) ]\n",
        "    print(\"original =\", len(df3_bid), \" ,bids filtered = \" , len(df3_bid_filtered), \" , percentage bids removed = \", ((len(df3_bid)-len(df3_bid_filtered)) /len(df3_bid))*100 )\n"
      ],
      "metadata": {
        "id": "I79YNYKuV_5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------cached image here ----------------\n",
        "\n",
        "[Bids_Filtered](https://imgur.com/a/BLM3356)\n"
      ],
      "metadata": {
        "id": "Dn44QfXI1A9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if len(df3_ask) > 20 :\n",
        "\n",
        "    df3_ask['rolling_median_3']=df3_ask['Value'].rolling(3).median()\n",
        "    df3_ask['rolling_mean_10']=df3_ask['Value'].rolling(10).mean()\n",
        "    df3_ask['rolling_std_10']=df3_ask['Value'].rolling(10).std()\n",
        "\n",
        "    df3_ask = df3_ask.dropna()\n",
        "\n",
        "    df3_ask['topline'] = df3_ask['rolling_mean_10'] + 1.0*df3_ask['rolling_std_10'] #filter band top = Rolling means + 1 x Moving Std Deviation\n",
        "    df3_ask['bottomline'] = df3_ask['rolling_mean_10'] - 1.0*df3_ask['rolling_std_10'] #filter band bottom = Rolling means - 1 x Moving Std Deviation\n",
        "\n",
        "    #We drop asks that are not in the range of the topline & bottomline bands\n",
        "    df3_ask_filtered = df3_ask.loc[(df3_ask['Value']<= df3_ask['topline']) & (df3_ask['Value'] >= df3_ask['bottomline']) ]\n",
        "\n",
        "    #let's see how much data we lost here\n",
        "    print(\"original =\", len(df3_ask), \" ,asks filtered = \" , len(df3_ask_filtered), \" , percentage ask removed = \", ((len(df3_ask)-len(df3_ask_filtered)) /len(df3_ask))*100 )\n",
        "\n",
        "\n",
        "\n",
        "    if DrawCharts == 1:\n",
        "        #let's plot the asks\n",
        "        plt.plot(df3_ask['TimestampUtc'], df3_ask['Value'],label=\"price\", color ='red' )\n",
        "        plt.plot(df3_ask['TimestampUtc'], df3_ask['topline'],label=\"top\" )\n",
        "        plt.plot(df3_ask['TimestampUtc'], df3_ask['bottomline'],label=\"bottom\" )\n",
        "        plt.xlabel(\"TimeStampUtc\", fontsize=10)\n",
        "        plt.ylabel(\"price\", fontsize=10)\n",
        "\n",
        "\n",
        "        plt.title(f\"Figure 3 - plot of STXE Tickdata Asks with filteration bands\",fontsize =14)\n",
        "        plt.legend(loc=\"upper left\")\n",
        "        plt.rcParams['figure.figsize'] = [25, 6]\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"----not enough asks to use moving averages------\")  #debug\n",
        "    df3_ask['mean'] = df3_ask['Value'].mean()\n",
        "    df3_ask['topline'] = df3_ask['Value'].mean()*1.1\n",
        "    df3_ask['bottomline'] = df3_ask['Value'].mean()*0.9\n",
        "    df3_ask_filtered = df3_ask.loc[(df3_ask['Value']<= df3_ask['topline']) & (df3_ask['Value'] >= df3_ask['bottomline']) ]\n",
        "    print(\"original =\", len(df3_ask), \" ,bids filtered = \" , len(df3_ask_filtered), \" , percentage bids removed = \", ((len(df3_ask)-len(df3_ask_filtered)) /len(df3_ask))*100 )\n"
      ],
      "metadata": {
        "id": "9wGop_eEYaP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------cached image-------------------\n",
        "\n",
        "[asks filtered](https://imgur.com/a/bmBxWxa)\n"
      ],
      "metadata": {
        "id": "JpV2rfhi1tIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last we look at Trades"
      ],
      "metadata": {
        "id": "pdim0oD7ZsjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if len(df3_trade) > 20 :\n",
        "    df3_trade['rolling_median_3']=df3_trade['Value'].rolling(3).median()\n",
        "    df3_trade['rolling_mean_10']=df3_trade['Value'].rolling(10).mean()\n",
        "    df3_trade['rolling_std_10']=df3_trade['Value'].rolling(10).std()\n",
        "\n",
        "    df3_trade = df3_trade.dropna()\n",
        "\n",
        "    df3_trade['topline'] = df3_trade['rolling_mean_10'] + 2*df3_trade['rolling_std_10']\n",
        "    df3_trade['bottomline'] = df3_trade['rolling_mean_10'] - 2*df3_trade['rolling_std_10']\n",
        "\n",
        "    #We drop trades that are not in the range of the topline & bottomline bands\n",
        "    df3_trade_filtered = df3_trade.loc[(df3_trade['Value']<= df3_trade['topline']) & (df3_trade['Value'] >= df3_trade['bottomline']) ]\n",
        "\n",
        "    #let's see how much data we lost here\n",
        "    print(\"original =\", len(df3_trade), \" ,trades filtered = \" , len(df3_trade_filtered), \" , percentage trades removed = \", ((len(df3_trade)-len(df3_trade_filtered)) /len(df3_trade))*100 )\n",
        "\n",
        "    if DrawCharts == 1:\n",
        "        #let's plot the trades\n",
        "        plt.plot(df3_trade['TimestampUtc'], df3_trade['Value'],label=\"price\", color='pink' )\n",
        "        plt.plot(df3_trade['TimestampUtc'], df3_trade['topline'],label=\"top\" )\n",
        "        plt.plot(df3_trade['TimestampUtc'], df3_trade['bottomline'],label=\"bottom\" )\n",
        "        plt.xlabel(\"TimeStampUtc\", fontsize=10)\n",
        "        plt.ylabel(\"price\", fontsize=10)\n",
        "\n",
        "        plt.title(f\"Plot of STXE Tickdata Trade\",fontsize =14)\n",
        "        plt.legend(loc=\"upper left\")\n",
        "\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"----not enough trades to use moving averages------\")  #debug\n",
        "    df3_trade['mean'] = df3_trade['Value'].mean()\n",
        "    df3_trade['topline'] = df3_trade['Value'].mean()*1.1\n",
        "    df3_trade['bottomline'] = df3_trade['Value'].mean()*0.9\n",
        "    df3_ask_filtered = df3_trade.loc[(df3_trade['Value']<= df3_trade['topline']) & (df3_trade['Value'] >= df3_trade['bottomline']) ]\n",
        "    print(\"original =\", len(df3_trade), \" ,bids filtered = \" , len(df3_ask_filtered), \" , percentage bids removed = \", ((len(df3_trade)-len(df3_ask_filtered)) /len(df3_trade))*100 )\n"
      ],
      "metadata": {
        "id": "Q79TrFRxZwcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------Cached Image----------\n",
        "\n",
        "[trades filtered](https://imgur.com/a/55U6ouW)"
      ],
      "metadata": {
        "id": "yrmFE9iq6uU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unioning the two dataframes\n",
        "df3_reunited = pd.concat([df3_bid_filtered,df3_ask_filtered, df3_trade_filtered])\n",
        "\n",
        "#estimating how much data we filtered out\n",
        "print(\"original =\", original_size, \" ,ticks filtered = \" , len(df3_reunited), \" , percentage ticks ask removed = \", ((original_size - len(df3_reunited))/ original_size)*100 )\n",
        "\n",
        "#and bringing back the original sort\n",
        "df3_final = df3_reunited.sort_values(by=['Index'])\n",
        "\n",
        "\n",
        "if DrawCharts == 1:\n",
        "    #let's plot this again\n",
        "    plt.plot(df3_final['TimestampUtc'], df3_final['Value'],label=\"filtered data\", color = 'green')\n",
        "\n",
        "    plt.xlabel(\"TimeStampUtc\", fontsize=10)\n",
        "    plt.ylabel(\"price\", fontsize=10)\n",
        "\n",
        "    plt.title(f\"Figure 4 - plot of STXE Tickdata filtered data\",fontsize =14)\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.rcParams['figure.figsize'] = [25, 6]\n",
        "\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "t3Yonk1Apn9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Removing Cross / Locked market quotes**\n",
        "\n"
      ],
      "metadata": {
        "id": "pV4BT_jk6jjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First we remove trades from the data, so we're only looking at ticks\n",
        "df4  = df3_final[df3_final['Type']!=\"Trade\"]\n",
        "df4_trades  = df3_final[df3_final['Type']==\"Trade\"]\n",
        "\n",
        "#we subset the data into its relavant components\n",
        "df5 = df4[['Index','TimestampUtc','Type','Value']]\n",
        "\n",
        "#we pivot the data, by time and create columns for Bid and Offers\n",
        "result = df5.assign(BID_PRICE=lambda df: df['Value'][df['Type'] == 'Bid'],\n",
        "                     ASK_PRICE=lambda df: df['Value'][df['Type'] == 'Ask'])\n",
        "#Let's look at this\n",
        "print(result.head())"
      ],
      "metadata": {
        "id": "RHzbhlY57r2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66dc1b38-79e9-4f23-f35e-2bddd47bcaa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Index              TimestampUtc Type  Value  BID_PRICE  ASK_PRICE\n",
            "36     37  20160222 07:00:03.936984  Ask   2890        NaN     2890.0\n",
            "38     39  20160222 07:00:03.936984  Ask   2890        NaN     2890.0\n",
            "39     40  20160222 07:00:03.936984  Ask   2884        NaN     2884.0\n",
            "43     44  20160222 07:00:03.936984  Ask   2885        NaN     2885.0\n",
            "46     47  20160222 07:00:03.936984  Ask   2886        NaN     2886.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we aggregate the date by each instance of time and maximum bids and offers at that time\n",
        "result_agg = result.groupby(['TimestampUtc']).agg({'BID_PRICE':'max','ASK_PRICE':'min'})\n",
        "\n",
        "#renaming the columns\n",
        "result_agg.rename(columns = {'BID_PRICE':'BID_MAX','ASK_PRICE':'ASK_MIN'}, inplace  = True)\n",
        "print(result_agg.head(25).to_string())"
      ],
      "metadata": {
        "id": "7sx-8uH0971k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438967ac-cfae-464e-8849-305a72f7e167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          BID_MAX  ASK_MIN\n",
            "TimestampUtc                              \n",
            "20160222 07:00:03.936984   2887.0   2884.0\n",
            "20160222 07:00:03.952609   2888.0   2888.0\n",
            "20160222 07:00:03.983860   2887.0   2888.0\n",
            "20160222 07:00:04.015110      NaN   2888.0\n",
            "20160222 07:00:04.030735      NaN   2888.0\n",
            "20160222 07:00:04.140113   2888.0   2889.0\n",
            "20160222 07:00:04.155738   2887.0   2889.0\n",
            "20160222 07:00:04.186988   2887.0      NaN\n",
            "20160222 07:00:04.233864   2887.0      NaN\n",
            "20160222 07:00:04.327616   2887.0      NaN\n",
            "20160222 07:00:04.468244   2887.0      NaN\n",
            "20160222 07:00:04.624497   2887.0   2888.0\n",
            "20160222 07:00:04.812000   2887.0      NaN\n",
            "20160222 07:00:04.890127      NaN   2888.0\n",
            "20160222 07:00:05.015129      NaN   2888.0\n",
            "20160222 07:00:05.046380   2887.0      NaN\n",
            "20160222 07:00:05.218258      NaN   2888.0\n",
            "20160222 07:00:05.265134      NaN   2888.0\n",
            "20160222 07:00:05.312011      NaN   2888.0\n",
            "20160222 07:00:06.171408   2886.0   2887.0\n",
            "20160222 07:00:06.390163      NaN   2887.0\n",
            "20160222 07:00:06.905801   2886.0      NaN\n",
            "20160222 07:00:07.171433   2886.0      NaN\n",
            "20160222 07:00:07.671446   2886.0      NaN\n",
            "20160222 07:00:08.046456   2887.0   2888.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We then calculate the spread (ASK_MAX minus BID_MAX) and discard the negative or zero values\n",
        "result_agg['SPREAD'] = result_agg['ASK_MIN']-result_agg['BID_MAX']\n",
        "res_sorted = result_agg.sort_values(by='SPREAD')\n",
        "\n",
        "print(res_sorted.head(30))"
      ],
      "metadata": {
        "id": "4AVBc--U_Tcn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "252c84c9-5ec8-4222-af35-0910e562ac19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          BID_MAX  ASK_MIN  SPREAD\n",
            "TimestampUtc                                      \n",
            "20160222 07:00:03.936984   2887.0   2884.0    -3.0\n",
            "20160222 08:16:00.089991   2915.0   2915.0     0.0\n",
            "20160222 08:16:36.622040   2914.0   2914.0     0.0\n",
            "20160222 07:00:09.952754   2888.0   2888.0     0.0\n",
            "20160222 07:00:10.655897   2887.0   2887.0     0.0\n",
            "20160222 07:00:10.780901   2884.0   2884.0     0.0\n",
            "20160222 07:00:11.734050   2885.0   2885.0     0.0\n",
            "20160222 07:00:12.093434   2885.0   2885.0     0.0\n",
            "20160222 07:00:12.312190   2885.0   2885.0     0.0\n",
            "20160222 08:15:35.777024   2915.0   2915.0     0.0\n",
            "20160222 08:15:35.823900   2915.0   2915.0     0.0\n",
            "20160222 08:16:36.668917   2914.0   2914.0     0.0\n",
            "20160222 08:17:21.685478   2914.0   2914.0     0.0\n",
            "20160222 08:17:23.622978   2914.0   2914.0     0.0\n",
            "20160222 08:17:32.185478   2914.0   2914.0     0.0\n",
            "20160222 08:17:39.701103   2915.0   2915.0     0.0\n",
            "20160222 08:15:44.652194   2914.0   2914.0     0.0\n",
            "20160222 08:15:17.558024   2914.0   2914.0     0.0\n",
            "20160222 08:15:17.589275   2914.0   2914.0     0.0\n",
            "20160222 08:15:17.667401   2914.0   2914.0     0.0\n",
            "20160222 08:15:35.105136   2915.0   2915.0     0.0\n",
            "20160222 08:15:35.261389   2915.0   2915.0     0.0\n",
            "20160222 08:15:35.386391   2915.0   2915.0     0.0\n",
            "20160222 08:15:35.730148   2915.0   2915.0     0.0\n",
            "20160222 08:15:35.745773   2915.0   2915.0     0.0\n",
            "20160222 08:19:15.937185   2921.0   2921.0     0.0\n",
            "20160222 08:18:08.873229   2916.0   2916.0     0.0\n",
            "20160222 08:18:08.904480   2916.0   2916.0     0.0\n",
            "20160222 08:18:13.717044   2918.0   2918.0     0.0\n",
            "20160222 08:18:32.654908   2918.0   2918.0     0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There appears to be a ton of data with SPREAD <= 0 an so let's extract them"
      ],
      "metadata": {
        "id": "6OR0i3se_9wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting rows where SPREAD <= 0\n",
        "res_lockMkt_discards = res_sorted[res_sorted['SPREAD']<=0]\n",
        "\n",
        "#Let's take a look at this data\n",
        "print(res_lockMkt_discards.head(10).to_string())\n"
      ],
      "metadata": {
        "id": "zg7Wd0tERopL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa22571e-b960-4d25-82c3-a641bed70c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          BID_MAX  ASK_MIN  SPREAD\n",
            "TimestampUtc                                      \n",
            "20160222 07:00:03.936984   2887.0   2884.0    -3.0\n",
            "20160222 08:16:00.089991   2915.0   2915.0     0.0\n",
            "20160222 08:16:36.622040   2914.0   2914.0     0.0\n",
            "20160222 07:00:09.952754   2888.0   2888.0     0.0\n",
            "20160222 07:00:10.655897   2887.0   2887.0     0.0\n",
            "20160222 07:00:10.780901   2884.0   2884.0     0.0\n",
            "20160222 07:00:11.734050   2885.0   2885.0     0.0\n",
            "20160222 07:00:12.093434   2885.0   2885.0     0.0\n",
            "20160222 07:00:12.312190   2885.0   2885.0     0.0\n",
            "20160222 08:15:35.777024   2915.0   2915.0     0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#We then extract the Timestamps into a list and use this to filter out the values we dont want\n",
        "time_stamps_to_be_discarded = res_lockMkt_discards.index\n",
        "\n",
        "#removing the crossed bid ask from the dataframe\n",
        "df4_after_discard = df4[~df4.TimestampUtc.isin(res_lockMkt_discards.index)]\n",
        "\n",
        "\n",
        "#Next let's look at some stats, to make sure we're not being too stringent (or not stringent enough)\n",
        "print(\"------a------\")\n",
        "print(\"lenght of ticks before discarding = \",len(df4))\n",
        "print(\"------b------\")\n",
        "original_time_intervals=len(result.groupby(['TimestampUtc']).size())\n",
        "print(\"the original number of time intervals = \",original_time_intervals)\n",
        "print(\"------c------\")\n",
        "print(\"the number of times intervals to be discarded = \", len(res_lockMkt_discards))\n",
        "print(\"------d------\")\n",
        "print(\"length of ticks after discarding cross markets = \", len(df4_after_discard))\n",
        "print(\"------e------\")\n",
        "time_intervals_left = len(df4_after_discard.groupby(['TimestampUtc']).size())\n",
        "print(\"the number of time intervals after discarding =\",time_intervals_left)\n",
        "print(\"------f------\")\n",
        "print(\"percentage of ticks discarded = \",  ((len(df4) - len(df4_after_discard))/ len(df4))  *100)\n",
        "print(\"------g------\")\n",
        "print(\"percentage of time intervals discarded = \",  ((original_time_intervals - time_intervals_left )/ original_time_intervals)  *100)"
      ],
      "metadata": {
        "id": "m1OwHac-SnxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fddee4e8-82a2-4581-e5c7-6ba8b763341c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bahahahah\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting aside the data with crossed market discards for bid ask bounce\n",
        "df4_after_discard_for_bid_ask_bounce = df4_after_discard.copy()\n",
        "\n",
        "#rejoining ticks after cross market discards to trades\n",
        "df4_reunited = pd.concat([df4_after_discard, df4_trades])\n",
        "\n",
        "#and bringing back the original sort\n",
        "df4_final = df4_reunited.sort_values(by=['Index'])\n",
        "\n",
        "\n",
        "#let's see what this looks like\n",
        "print(df4_final.head(10).to_string())\n",
        "\n",
        "#total ticks discarded\n",
        "print(\"-----PERCENTAGE TOTAL TICKS DISCARDED -------- \",round(((original_size - len(df4_final)) / original_size)*100,2))\n",
        "\n",
        "#RESULT SET 1\n",
        "print('Final dataframe = ', df4_final)"
      ],
      "metadata": {
        "id": "_GmL_6fUW4bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bid Ask Bounce**\n",
        "\n",
        "the \"bid-ask bounce\" describes a frequent pattern in financial markets where the price of a stock or other asset jumps back and forth between the buy price (bid) and sell price (ask). This happens because trades can occur at either the bid or ask price, even if there's no significant news or change in value. This bouncing price movement doesn't necessarily reflect the actual value of the asset, but rather the current buying and selling activity.\n",
        "\n",
        "\n",
        "Traditionally, the back-and-forth price movements between the buy and sell price (bid-ask bounce) haven't been considered valuable information. In fact, they can be misleading, suggesting price changes when none actually happen. Therefore, it's important to find ways to filter out or minimize the impact of these bounces on the data. Luckily, there are several methods available to achieve this.-- This is an entire complex subject, but given the lack of time, let's simply calculate the Midquote price\n",
        "\n",
        "Midquote = (Best Bid + Best Offer) / 2\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Xm9W84FbXC9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#We start a new datafreame df6 which has all the cross- market quotes filtered out.\n",
        "df6 = df4_after_discard_for_bid_ask_bounce[['Id','Index','TimestampUtc','Type','Size','Value']]\n",
        "\n",
        "#let's see what this looks like\n",
        "print(df6.head(10).to_string())\n"
      ],
      "metadata": {
        "id": "cGjxVg_DY5Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#we pivot the data, by time and create columns for Bid and Offers\n",
        "df6_pivot = df6.assign(BID_PRICE=lambda df6: df6['Value'][df6['Type'] == 'Bid'],\n",
        "                     ASK_PRICE=lambda df6: df6['Value'][df6['Type'] == 'Ask'])\n",
        "#Let's look at this\n",
        "print(df6_pivot.head(20).to_string())"
      ],
      "metadata": {
        "id": "4q7qwvbtZZHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we aggregate the date by each instance of time and maximum bids and offers at that time\n",
        "df6_agg = df6_pivot.groupby(['TimestampUtc']).agg({'BID_PRICE':'max','ASK_PRICE':'min'}) ##orginal\n",
        "\n",
        "df6_agg.rename(columns = {'BID_PRICE':'BID_MAX','ASK_PRICE':'ASK_MIN'}, inplace  = True)\n",
        "\n",
        "#fill all the zeros\n",
        "df6_agg = df6_agg.fillna(0)\n",
        "\n",
        "#Let's see what this looks like\n",
        "print(df6_agg.head(25).to_string())\n"
      ],
      "metadata": {
        "id": "2gfdJmwSZig3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Function for lamda to determine midprice in the event there are no bids or ask at a certain instant.\n",
        "def FnDetermineMidPrice(BIDMAX,ASKMIN):\n",
        "    if BIDMAX == 0:\n",
        "        BIDMAX = ASKMIN\n",
        "\n",
        "    if  ASKMIN == 0:\n",
        "          ASKMIN = BIDMAX\n",
        "\n",
        "    return (BIDMAX + ASKMIN)/2"
      ],
      "metadata": {
        "id": "XLgb2HRXZl7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df6_agg['midprice'] = df6_agg.apply(lambda x:FnDetermineMidPrice(x.BID_MAX, x.ASK_MIN),axis=1)\n",
        "\n",
        "#Let's see what this looks like\n",
        "print(df6_agg.head(25).to_string())"
      ],
      "metadata": {
        "id": "xcrQfx6_Zwtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##RESULT SET 2\n",
        "print('Final dataframe  2 with BID-ASK Bounce smooted out = ', df6_agg)"
      ],
      "metadata": {
        "id": "bPa-Gg-EZydl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}